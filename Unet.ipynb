{"cells":[{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:03.050091Z","iopub.status.busy":"2023-11-16T15:29:03.049209Z","iopub.status.idle":"2023-11-16T15:29:26.772027Z","shell.execute_reply":"2023-11-16T15:29:26.770861Z","shell.execute_reply.started":"2023-11-16T15:29:03.050053Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torchsummary in /opt/conda/lib/python3.10/site-packages (1.5.1)\n","Requirement already satisfied: torchgeometry in /opt/conda/lib/python3.10/site-packages (0.1.2)\n","Requirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from torchgeometry) (2.0.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.12.2)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (4.5.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.1.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->torchgeometry) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->torchgeometry) (1.3.0)\n"]}],"source":["!pip install torchsummary\n","!pip install torchgeometry"]},{"cell_type":"code","execution_count":72,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-16T15:29:26.778639Z","iopub.status.busy":"2023-11-16T15:29:26.778270Z","iopub.status.idle":"2023-11-16T15:29:26.787627Z","shell.execute_reply":"2023-11-16T15:29:26.786526Z","shell.execute_reply.started":"2023-11-16T15:29:26.778604Z"},"trusted":true},"outputs":[],"source":["from torchsummary import summary\n","from torchgeometry.losses import one_hot\n","import os\n","import pandas as pd\n","import numpy as np\n","from PIL import Image\n","import cv2\n","import time\n","import imageio\n","import matplotlib.pyplot as plt\n","import time\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch import Tensor\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from torchvision.transforms import Resize, PILToTensor, ToPILImage, Compose, InterpolationMode\n","from collections import OrderedDict\n","import wandb"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:26.789396Z","iopub.status.busy":"2023-11-16T15:29:26.789041Z","iopub.status.idle":"2023-11-16T15:29:27.835361Z","shell.execute_reply":"2023-11-16T15:29:27.834176Z","shell.execute_reply.started":"2023-11-16T15:29:26.789363Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["GPU 0: Tesla T4 (UUID: GPU-accff986-184c-ae49-d261-9de16fe0ca42)\n","GPU 1: Tesla T4 (UUID: GPU-6a608521-7b64-aeb1-d4c6-c9257a82b24b)\n"]}],"source":["!nvidia-smi -L"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:27.839907Z","iopub.status.busy":"2023-11-16T15:29:27.839465Z","iopub.status.idle":"2023-11-16T15:29:27.849677Z","shell.execute_reply":"2023-11-16T15:29:27.847778Z","shell.execute_reply.started":"2023-11-16T15:29:27.839864Z"},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"markdown","metadata":{},"source":["# Parameters"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:27.851748Z","iopub.status.busy":"2023-11-16T15:29:27.851376Z","iopub.status.idle":"2023-11-16T15:29:27.859516Z","shell.execute_reply":"2023-11-16T15:29:27.858342Z","shell.execute_reply.started":"2023-11-16T15:29:27.851720Z"},"trusted":true},"outputs":[],"source":["# Number of class in the data set (3: neoplastic, non neoplastic, background)\n","num_classes = 3\n","\n","# Number of epoch\n","epochs = 50\n","\n","# Hyperparameters for training \n","learning_rate = 2e-04\n","batch_size = 4\n","display_step = 50\n","\n","# Model path\n","checkpoint_path = '/kaggle/working/unet_model.pth'\n","pretrained_path = \"/kaggle/input/unet-checkpoint/unet_model.pth\"\n","\n","# Initialize lists to keep track of loss and accuracy\n","loss_epoch_array = []\n","train_accuracy = []\n","test_accuracy = []\n","valid_accuracy = []"]},{"cell_type":"markdown","metadata":{},"source":["# Dataloader"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:27.861478Z","iopub.status.busy":"2023-11-16T15:29:27.861161Z","iopub.status.idle":"2023-11-16T15:29:27.870277Z","shell.execute_reply":"2023-11-16T15:29:27.869442Z","shell.execute_reply.started":"2023-11-16T15:29:27.861455Z"},"trusted":true},"outputs":[],"source":["transform = Compose([Resize((224, 224), interpolation=InterpolationMode.BILINEAR),\n","                     transforms.RandomVerticalFlip(p=0.5),\n","                     transforms.RandomHorizontalFlip(p=0.5),\n","                     transforms.RandomRotation(degrees=15),\n","                     PILToTensor()])\n","\n","val_transform = Compose([\n","    Resize((224, 224), interpolation=InterpolationMode.BILINEAR),\n","    PILToTensor()\n","])\n"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:27.871891Z","iopub.status.busy":"2023-11-16T15:29:27.871630Z","iopub.status.idle":"2023-11-16T15:29:27.884281Z","shell.execute_reply":"2023-11-16T15:29:27.883405Z","shell.execute_reply.started":"2023-11-16T15:29:27.871869Z"},"trusted":true},"outputs":[],"source":["class UNetDataClass(Dataset):\n","    def __init__(self, images_path, masks_path, transform):\n","        super(UNetDataClass, self).__init__()\n","        \n","        images_list = os.listdir(images_path)\n","        masks_list = os.listdir(masks_path)\n","        \n","        images_list = [images_path + image_name for image_name in images_list]\n","        masks_list = [masks_path + mask_name for mask_name in masks_list]\n","        \n","        self.images_list = images_list\n","        self.masks_list = masks_list\n","        self.transform = transform\n","        \n","    def __getitem__(self, index):\n","        img_path = self.images_list[index]\n","        mask_path = self.masks_list[index]\n","        \n","        # Open image and mask\n","        data = Image.open(img_path)\n","        label = Image.open(mask_path)\n","        \n","        # Normalize\n","        data = self.transform(data) / 255\n","        label = self.transform(label) / 255\n","        \n","        label = torch.where(label>0.65, 1.0, 0.0)\n","        \n","        label[2, :, :] = 0.0001\n","        label = torch.argmax(label, 0).type(torch.int64)\n","        \n","        return data, label\n","    \n","    def __len__(self):\n","        return len(self.images_list)"]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:27.885996Z","iopub.status.busy":"2023-11-16T15:29:27.885661Z","iopub.status.idle":"2023-11-16T15:29:27.898081Z","shell.execute_reply":"2023-11-16T15:29:27.897098Z","shell.execute_reply.started":"2023-11-16T15:29:27.885969Z"},"trusted":true},"outputs":[],"source":["images_path = \"/kaggle/input/bkai-igh-neopolyp/train/train/\"\n","masks_path =  \"/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt/\""]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:27.899504Z","iopub.status.busy":"2023-11-16T15:29:27.899252Z","iopub.status.idle":"2023-11-16T15:29:27.908060Z","shell.execute_reply":"2023-11-16T15:29:27.906939Z","shell.execute_reply.started":"2023-11-16T15:29:27.899482Z"},"trusted":true},"outputs":[],"source":["# unet_dataset = UNetDataClass(images_path, masks_path, transform)"]},{"cell_type":"code","execution_count":80,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:27.911850Z","iopub.status.busy":"2023-11-16T15:29:27.911525Z","iopub.status.idle":"2023-11-16T15:29:27.924876Z","shell.execute_reply":"2023-11-16T15:29:27.923854Z","shell.execute_reply.started":"2023-11-16T15:29:27.911823Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import ConcatDataset\n","not_aug_unet_dataset = UNetDataClass(images_path,masks_path,\n","                             transform = val_transform)\n","aug__unet_dataset = UNetDataClass(images_path,masks_path,\n","                             transform = transform)\n","unet_dataset = ConcatDataset([not_aug_dataset, aug_dataset])\n","\n"]},{"cell_type":"code","execution_count":81,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:27.927225Z","iopub.status.busy":"2023-11-16T15:29:27.926630Z","iopub.status.idle":"2023-11-16T15:29:27.932284Z","shell.execute_reply":"2023-11-16T15:29:27.931301Z","shell.execute_reply.started":"2023-11-16T15:29:27.927188Z"},"trusted":true},"outputs":[],"source":["train_size = 0.8\n","valid_size = 0.2"]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:27.934398Z","iopub.status.busy":"2023-11-16T15:29:27.933809Z","iopub.status.idle":"2023-11-16T15:29:27.942513Z","shell.execute_reply":"2023-11-16T15:29:27.941537Z","shell.execute_reply.started":"2023-11-16T15:29:27.934363Z"},"trusted":true},"outputs":[],"source":["train_set, valid_set = random_split(unet_dataset, \n","                                    [int(train_size * len(unet_dataset)) , \n","                                     int(valid_size * len(unet_dataset))])"]},{"cell_type":"code","execution_count":83,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:27.944017Z","iopub.status.busy":"2023-11-16T15:29:27.943726Z","iopub.status.idle":"2023-11-16T15:29:27.953219Z","shell.execute_reply":"2023-11-16T15:29:27.951912Z","shell.execute_reply.started":"2023-11-16T15:29:27.943994Z"},"trusted":true},"outputs":[],"source":["train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n","valid_dataloader = DataLoader(valid_set, batch_size=batch_size, shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["# Loss function"]},{"cell_type":"code","execution_count":84,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:27.954902Z","iopub.status.busy":"2023-11-16T15:29:27.954589Z","iopub.status.idle":"2023-11-16T15:29:27.968308Z","shell.execute_reply":"2023-11-16T15:29:27.967324Z","shell.execute_reply.started":"2023-11-16T15:29:27.954872Z"},"trusted":true},"outputs":[],"source":["class CEDiceLoss(nn.Module):\n","    def __init__(self, weights) -> None:\n","        super(CEDiceLoss, self).__init__()\n","        self.eps: float = 1e-6\n","        self.weights: torch.Tensor = weights\n","\n","    def forward(\n","            self,\n","            input: torch.Tensor,\n","            target: torch.Tensor) -> torch.Tensor:\n","        if not torch.is_tensor(input):\n","            raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n","                            .format(type(input)))\n","        if not len(input.shape) == 4:\n","            raise ValueError(\"Invalid input shape, we expect BxNxHxW. Got: {}\"\n","                             .format(input.shape))\n","        if not input.shape[-2:] == target.shape[-2:]:\n","            raise ValueError(\"input and target shapes must be the same. Got: {}\"\n","                             .format(input.shape, input.shape))\n","        if not input.device == target.device:\n","            raise ValueError(\n","                \"input and target must be in the same device. Got: {}\" .format(\n","                    input.device, target.device))\n","        if not self.weights.shape[1] == input.shape[1]:\n","            raise ValueError(\"The number of weights must equal the number of classes\")\n","        if not torch.sum(self.weights).item() == 1:\n","            raise ValueError(\"The sum of all weights must equal 1\")\n","            \n","        # cross entropy loss\n","        celoss = nn.CrossEntropyLoss(self.weights)(input, target)\n","        \n","        # compute softmax over the classes axis\n","        input_soft = F.softmax(input, dim=1)\n","\n","        # create the labels one hot tensor\n","        target_one_hot = one_hot(target, num_classes=input.shape[1],\n","                                 device=input.device, dtype=input.dtype)\n","\n","        # compute the actual dice score\n","        dims = (2, 3)\n","        intersection = torch.sum(input_soft * target_one_hot, dims)\n","        cardinality = torch.sum(input_soft + target_one_hot, dims)\n","\n","        dice_score = 2. * intersection / (cardinality + self.eps)\n","        \n","        dice_score = torch.sum(dice_score * self.weights, dim=1)\n","        \n","        return torch.mean(1. - dice_score) + celoss"]},{"cell_type":"code","execution_count":85,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:27.970915Z","iopub.status.busy":"2023-11-16T15:29:27.970002Z","iopub.status.idle":"2023-11-16T15:29:27.982192Z","shell.execute_reply":"2023-11-16T15:29:27.981319Z","shell.execute_reply.started":"2023-11-16T15:29:27.970883Z"},"trusted":true},"outputs":[],"source":["class FocalLoss(nn.Module):\n","    def __init__(self, weights=None, gamma=2.0):\n","        super(FocalLoss, self).__init__()\n","        self.gamma = gamma\n","        self.weights = weights\n","\n","    def forward(\n","        self,\n","        input: torch.Tensor,\n","        target: torch.Tensor\n","    ) -> torch.Tensor:\n","        if not torch.is_tensor(input):\n","            raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n","                            .format(type(input)))\n","        if not len(input.shape) == 4:\n","            raise ValueError(\"Invalid input shape, we expect BxNxHxW. Got: {}\"\n","                             .format(input.shape))\n","        if not input.shape[-2:] == target.shape[-2:]:\n","            raise ValueError(\"Input and target shapes must be the same. Got: {}\"\n","                             .format(input.shape, input.shape))\n","        if not input.device == target.device:\n","            raise ValueError(\n","                \"Input and target must be on the same device. Got: {}\" .format(\n","                    input.device, target.device))\n","        if self.weights is not None and not self.weights.shape[1] == input.shape[1]:\n","            raise ValueError(\"The number of weights must equal the number of classes\")\n","        if self.weights is not None and not torch.sum(self.weights).item() == 1:\n","            raise ValueError(\"The sum of all weights must equal 1\")\n","            \n","        # Focal loss\n","        ce_loss = F.cross_entropy(input, target, weight=self.weights)\n","        pt = torch.exp(-ce_loss)\n","        focal_loss = (1 - pt) ** self.gamma * ce_loss\n","\n","        return focal_loss"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"markdown","metadata":{},"source":["**Initialize weights**"]},{"cell_type":"code","execution_count":86,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:27.983901Z","iopub.status.busy":"2023-11-16T15:29:27.983527Z","iopub.status.idle":"2023-11-16T15:29:27.993536Z","shell.execute_reply":"2023-11-16T15:29:27.992346Z","shell.execute_reply.started":"2023-11-16T15:29:27.983869Z"},"trusted":true},"outputs":[],"source":["def weights_init(model):\n","    if isinstance(model, nn.Linear):\n","        # Xavier Distribution\n","        torch.nn.init.xavier_uniform_(model.weight)"]},{"cell_type":"code","execution_count":87,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:27.995604Z","iopub.status.busy":"2023-11-16T15:29:27.994961Z","iopub.status.idle":"2023-11-16T15:29:28.007241Z","shell.execute_reply":"2023-11-16T15:29:28.006176Z","shell.execute_reply.started":"2023-11-16T15:29:27.995553Z"},"trusted":true},"outputs":[],"source":["def save_model(model, optimizer, path):\n","    checkpoint = {\n","        \"model\": model.state_dict(),\n","        \"optimizer\": optimizer.state_dict(),\n","    }\n","    torch.save(checkpoint, path)\n","\n","def load_model(model, optimizer, path):\n","    checkpoint = torch.load(path)\n","    model.load_state_dict(checkpoint[\"model\"])\n","    optimizer.load_state_dict(checkpoint['optimizer'])\n","    return model, optimizer"]},{"cell_type":"markdown","metadata":{},"source":["**Train model**"]},{"cell_type":"code","execution_count":88,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:28.010335Z","iopub.status.busy":"2023-11-16T15:29:28.009333Z","iopub.status.idle":"2023-11-16T15:29:28.023705Z","shell.execute_reply":"2023-11-16T15:29:28.022677Z","shell.execute_reply.started":"2023-11-16T15:29:28.010303Z"},"trusted":true},"outputs":[],"source":["# Train function for each epoch\n","def train(train_dataloader, valid_dataloader,learing_rate_scheduler, epoch, display_step):\n","    print(f\"Start epoch #{epoch+1}, learning rate for this epoch: {learing_rate_scheduler.get_last_lr()}\")\n","    start_time = time.time()\n","    train_loss_epoch = 0\n","    test_loss_epoch = 0\n","    last_loss = 999999999\n","    model.train()\n","    for i, (data,targets) in enumerate(train_dataloader):\n","        \n","        # Load data into GPU\n","        data, targets = data.to(device), targets.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(data)\n","\n","        # Backpropagation, compute gradients\n","        loss = loss_function(outputs, targets.long())\n","        loss.backward()\n","\n","        # Apply gradients\n","        optimizer.step()\n","        \n","        # Save loss\n","        train_loss_epoch += loss.item()\n","        if (i+1) % display_step == 0:\n","#             accuracy = float(test(test_loader))\n","            print('Train Epoch: {} [{}/{} ({}%)]\\tLoss: {:.4f}'.format(\n","                epoch + 1, (i+1) * len(data), len(train_dataloader.dataset), 100 * (i+1) * len(data) / len(train_dataloader.dataset), \n","                loss.item()))\n","                  \n","    print(f\"Done epoch #{epoch+1}, time for this epoch: {time.time()-start_time}s\")\n","    train_loss_epoch/= (i + 1)\n","    \n","    # Evaluate the validation set\n","    model.eval()\n","    with torch.no_grad():\n","        for data, target in valid_dataloader:\n","            data, target = data.to(device), target.to(device)\n","            test_output = model(data)\n","            test_loss = loss_function(test_output, target)\n","            test_loss_epoch += test_loss.item()\n","            \n","    test_loss_epoch/= (i+1)\n","    \n","    return train_loss_epoch , test_loss_epoch"]},{"cell_type":"code","execution_count":89,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:28.025797Z","iopub.status.busy":"2023-11-16T15:29:28.024989Z","iopub.status.idle":"2023-11-16T15:29:28.036856Z","shell.execute_reply":"2023-11-16T15:29:28.035916Z","shell.execute_reply.started":"2023-11-16T15:29:28.025759Z"},"trusted":true},"outputs":[],"source":["# Test function\n","def test(dataloader):\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for i, (data, targets) in enumerate(dataloader):\n","            data, targets = data.to(device), targets.to(device)\n","            outputs = model(data)\n","            _, pred = torch.max(outputs, 1)\n","            test_loss += targets.size(0)\n","            correct += torch.sum(pred == targets).item()\n","    return 100.0 * correct / test_loss"]},{"cell_type":"code","execution_count":90,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:28.038370Z","iopub.status.busy":"2023-11-16T15:29:28.038033Z","iopub.status.idle":"2023-11-16T15:29:40.188171Z","shell.execute_reply":"2023-11-16T15:29:40.186957Z","shell.execute_reply.started":"2023-11-16T15:29:28.038340Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: segmentation-models-pytorch in /opt/conda/lib/python3.10/site-packages (0.3.3)\n","Requirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.15.1)\n","Requirement already satisfied: pretrainedmodels==0.7.4 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.7.4)\n","Requirement already satisfied: efficientnet-pytorch==0.7.1 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.7.1)\n","Requirement already satisfied: timm==0.9.2 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.9.2)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.66.1)\n","Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (10.1.0)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.0.0)\n","Requirement already satisfied: munch in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.0.0)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.17.3)\n","Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.0)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.24.3)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.31.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.12.2)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.5.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2023.10.0)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (21.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2023.7.22)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.0.9)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n"]}],"source":["!pip install segmentation-models-pytorch"]},{"cell_type":"code","execution_count":91,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:40.190263Z","iopub.status.busy":"2023-11-16T15:29:40.189871Z","iopub.status.idle":"2023-11-16T15:29:41.278707Z","shell.execute_reply":"2023-11-16T15:29:41.277634Z","shell.execute_reply.started":"2023-11-16T15:29:40.190226Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n","100%|██████████| 83.3M/83.3M [00:00<00:00, 242MB/s] \n"]}],"source":["import segmentation_models_pytorch as smp\n","model = smp.UnetPlusPlus(\n","    encoder_name=\"resnet34\",        \n","    encoder_weights=\"imagenet\",     \n","    in_channels=3,                  \n","    classes=3     \n",")"]},{"cell_type":"code","execution_count":92,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:41.280360Z","iopub.status.busy":"2023-11-16T15:29:41.280061Z","iopub.status.idle":"2023-11-16T15:29:41.333901Z","shell.execute_reply":"2023-11-16T15:29:41.332770Z","shell.execute_reply.started":"2023-11-16T15:29:41.280333Z"},"trusted":true},"outputs":[{"data":{"text/plain":["UnetPlusPlus(\n","  (encoder): ResNetEncoder(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (4): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (5): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (decoder): UnetPlusPlusDecoder(\n","    (center): Identity()\n","    (blocks): ModuleDict(\n","      (x_0_0): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","      (x_0_1): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","      (x_1_1): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","      (x_0_2): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","      (x_1_2): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","      (x_2_2): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","      (x_0_3): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(320, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","      (x_1_3): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","      (x_2_3): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","      (x_3_3): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","      (x_0_4): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","    )\n","  )\n","  (segmentation_head): SegmentationHead(\n","    (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): Identity()\n","    (2): Activation(\n","      (activation): Identity()\n","    )\n","  )\n",")"]},"execution_count":92,"metadata":{},"output_type":"execute_result"}],"source":["\n","model.to(device)"]},{"cell_type":"code","execution_count":93,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:41.335701Z","iopub.status.busy":"2023-11-16T15:29:41.335318Z","iopub.status.idle":"2023-11-16T15:29:41.659492Z","shell.execute_reply":"2023-11-16T15:29:41.658471Z","shell.execute_reply.started":"2023-11-16T15:29:41.335667Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input ['bkai-igh-neopolyp']\n","/kaggle/input/bkai-igh-neopolyp ['train_gt', 'test', 'train']\n","/kaggle/input/bkai-igh-neopolyp/train_gt ['train_gt']\n","/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt []\n","/kaggle/input/bkai-igh-neopolyp/test ['test']\n","/kaggle/input/bkai-igh-neopolyp/test/test []\n","/kaggle/input/bkai-igh-neopolyp/train ['train']\n","/kaggle/input/bkai-igh-neopolyp/train/train []\n"]}],"source":["count = 0\n","for root, folders, filenames in os.walk('/kaggle/input'):\n","   print(root, folders)"]},{"cell_type":"code","execution_count":94,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:41.661275Z","iopub.status.busy":"2023-11-16T15:29:41.660921Z","iopub.status.idle":"2023-11-16T15:29:41.672350Z","shell.execute_reply":"2023-11-16T15:29:41.671163Z","shell.execute_reply.started":"2023-11-16T15:29:41.661241Z"},"trusted":true},"outputs":[],"source":["weights = torch.Tensor([[0.4, 0.55, 0.05]]).cuda()\n","loss_function = CEDiceLoss(weights)\n","\n","# Define the optimizer (Adam optimizer)\n","optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n","# optimizer.load_state_dict(checkpoint['optimizer'])\n","\n","# Learning rate scheduler\n","learing_rate_scheduler = lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.6)"]},{"cell_type":"code","execution_count":95,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:41.674805Z","iopub.status.busy":"2023-11-16T15:29:41.674029Z","iopub.status.idle":"2023-11-16T15:29:41.977196Z","shell.execute_reply":"2023-11-16T15:29:41.975997Z","shell.execute_reply.started":"2023-11-16T15:29:41.674770Z"},"trusted":true},"outputs":[],"source":["save_model(model, optimizer, checkpoint_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:29:41.981314Z","iopub.status.busy":"2023-11-16T15:29:41.981005Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"]},{"data":{"text/html":["Finishing last run (ID:bx06lx9u) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train loss</td><td>█▄▄▃▃▂▂▂▁▁</td></tr><tr><td>Valid loss</td><td>▅█▃▃▄▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train loss</td><td>0.04741</td></tr><tr><td>Valid loss</td><td>0.01054</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">still-vortex-12</strong> at: <a href='https://wandb.ai/tuandatebayo/PolypSegment/runs/bx06lx9u' target=\"_blank\">https://wandb.ai/tuandatebayo/PolypSegment/runs/bx06lx9u</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20231116_143416-bx06lx9u/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:bx06lx9u). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["wandb version 0.16.0 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.15.12"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20231116_152942-0mbrdahd</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/tuandatebayo/PolypSegment/runs/0mbrdahd' target=\"_blank\">eternal-mountain-14</a></strong> to <a href='https://wandb.ai/tuandatebayo/PolypSegment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/tuandatebayo/PolypSegment' target=\"_blank\">https://wandb.ai/tuandatebayo/PolypSegment</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/tuandatebayo/PolypSegment/runs/0mbrdahd' target=\"_blank\">https://wandb.ai/tuandatebayo/PolypSegment/runs/0mbrdahd</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Start epoch #1, learning rate for this epoch: [0.0002]\n","Train Epoch: 1 [200/1600 (12.5%)]\tLoss: 1.6566\n","Train Epoch: 1 [400/1600 (25.0%)]\tLoss: 1.5472\n","Train Epoch: 1 [600/1600 (37.5%)]\tLoss: 1.1831\n","Train Epoch: 1 [800/1600 (50.0%)]\tLoss: 1.1711\n","Train Epoch: 1 [1000/1600 (62.5%)]\tLoss: 1.5482\n","Train Epoch: 1 [1200/1600 (75.0%)]\tLoss: 1.7197\n","Train Epoch: 1 [1400/1600 (87.5%)]\tLoss: 1.3118\n","Train Epoch: 1 [1600/1600 (100.0%)]\tLoss: 1.7296\n","Done epoch #1, time for this epoch: 95.69400191307068s\n","Start epoch #2, learning rate for this epoch: [0.0002]\n","Train Epoch: 2 [200/1600 (12.5%)]\tLoss: 1.7873\n","Train Epoch: 2 [400/1600 (25.0%)]\tLoss: 1.0437\n","Train Epoch: 2 [600/1600 (37.5%)]\tLoss: 1.2561\n","Train Epoch: 2 [800/1600 (50.0%)]\tLoss: 1.0413\n","Train Epoch: 2 [1000/1600 (62.5%)]\tLoss: 1.2718\n","Train Epoch: 2 [1200/1600 (75.0%)]\tLoss: 0.9179\n","Train Epoch: 2 [1400/1600 (87.5%)]\tLoss: 1.2964\n","Train Epoch: 2 [1600/1600 (100.0%)]\tLoss: 1.1951\n","Done epoch #2, time for this epoch: 95.7796311378479s\n","Start epoch #3, learning rate for this epoch: [0.0002]\n","Train Epoch: 3 [200/1600 (12.5%)]\tLoss: 0.9247\n","Train Epoch: 3 [400/1600 (25.0%)]\tLoss: 1.0365\n","Train Epoch: 3 [600/1600 (37.5%)]\tLoss: 0.8920\n","Train Epoch: 3 [800/1600 (50.0%)]\tLoss: 1.0192\n","Train Epoch: 3 [1000/1600 (62.5%)]\tLoss: 1.1115\n","Train Epoch: 3 [1200/1600 (75.0%)]\tLoss: 1.4992\n","Train Epoch: 3 [1400/1600 (87.5%)]\tLoss: 1.3356\n","Train Epoch: 3 [1600/1600 (100.0%)]\tLoss: 1.9407\n","Done epoch #3, time for this epoch: 94.87798285484314s\n","Start epoch #4, learning rate for this epoch: [0.0002]\n","Train Epoch: 4 [200/1600 (12.5%)]\tLoss: 1.4111\n","Train Epoch: 4 [400/1600 (25.0%)]\tLoss: 1.0567\n","Train Epoch: 4 [600/1600 (37.5%)]\tLoss: 1.1035\n","Train Epoch: 4 [800/1600 (50.0%)]\tLoss: 0.9860\n","Train Epoch: 4 [1000/1600 (62.5%)]\tLoss: 0.9696\n","Train Epoch: 4 [1200/1600 (75.0%)]\tLoss: 0.9815\n","Train Epoch: 4 [1400/1600 (87.5%)]\tLoss: 1.0237\n","Train Epoch: 4 [1600/1600 (100.0%)]\tLoss: 1.4907\n","Done epoch #4, time for this epoch: 95.72181940078735s\n","Start epoch #5, learning rate for this epoch: [0.00012]\n","Train Epoch: 5 [200/1600 (12.5%)]\tLoss: 0.8786\n","Train Epoch: 5 [400/1600 (25.0%)]\tLoss: 1.0501\n","Train Epoch: 5 [600/1600 (37.5%)]\tLoss: 1.4136\n","Train Epoch: 5 [800/1600 (50.0%)]\tLoss: 0.7617\n","Train Epoch: 5 [1000/1600 (62.5%)]\tLoss: 0.7904\n","Train Epoch: 5 [1200/1600 (75.0%)]\tLoss: 1.1809\n"]}],"source":["wandb.login(\n","    # set the wandb project where this run will be logged\n","#     project= \"PolypSegment\", \n","    key = \"bc244be18c8a532993c559a3fa44acd1cd47486a\",\n",")\n","wandb.init(\n","    project = \"PolypSegment\"\n",")\n","# Training loop\n","train_loss_array = []\n","test_loss_array = []\n","last_loss = 9999999999999\n","for epoch in range(epochs):\n","    train_loss_epoch = 0\n","    test_loss_epoch = 0\n","    (train_loss_epoch, test_loss_epoch) = train(train_dataloader, \n","                                              valid_dataloader, \n","                                              learing_rate_scheduler, epoch, display_step)\n","    \n","    if test_loss_epoch < last_loss:\n","        save_model(model, optimizer, checkpoint_path)\n","        last_loss = test_loss_epoch\n","        \n","    learing_rate_scheduler.step()\n","    train_loss_array.append(train_loss_epoch)\n","    test_loss_array.append(test_loss_epoch)\n","    wandb.log({\"Train loss\": train_loss_epoch, \"Valid loss\": test_loss_epoch})\n","#     train_accuracy.append(test(train_loader))\n","#     valid_accuracy.append(test(test_loader))\n","#     print(\"Epoch {}: loss: {:.4f}, train accuracy: {:.4f}, valid accuracy:{:.4f}\".format(epoch + 1, \n","#                                         train_loss_array[-1], train_accuracy[-1], valid_accuracy[-1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Plot the learning cure"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# load_model(model, checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.rcParams['figure.dpi'] = 90\n","plt.rcParams['figure.figsize'] = (6, 4)\n","epochs_array = range(epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plot Training and Test loss\n","plt.plot(epochs_array, train_loss_array, 'g', label='Training loss')\n","# plt.plot(epochs_array, test_loss_array, 'b', label='Test loss')\n","plt.title('Training and Test loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["**Infer**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# from torch.jit import load\n","# model = UNet()\n","# optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n","\n","# checkpoint = torch.load(pretrained_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# optimizer.load_state_dict(checkpoint['optimizer'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# from collections import OrderedDict\n","# new_state_dict = OrderedDict()\n","# for k, v in checkpoint['model'].items():\n","#     name = k[7:] # remove `module.`\n","#     new_state_dict[name] = v\n","# # load params\n","# model.load_state_dict(new_state_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["**Visualize results**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for i, (data, label) in enumerate(train_dataloader):\n","    img = data\n","    mask = label\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig, arr = plt.subplots(4, 3, figsize=(16, 12))\n","arr[0][0].set_title('Image')\n","arr[0][1].set_title('Segmentation')\n","arr[0][2].set_title('Predict')\n","\n","model.eval()\n","with torch.no_grad():\n","    predict = model(img.to(device))\n","\n","for i in range(4):\n","    arr[i][0].imshow(img[i].permute(1, 2, 0));\n","    \n","    arr[i][1].imshow(F.one_hot(mask[i]).float())\n","    \n","    arr[i][2].imshow(F.one_hot(torch.argmax(predict[i], 0).cpu()).float())"]},{"cell_type":"markdown","metadata":{},"source":["**Create submission**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["transform = Compose([Resize((224, 224), interpolation=InterpolationMode.BILINEAR),\n","                     PILToTensor()])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class UNetTestDataClass(Dataset):\n","    def __init__(self, images_path, transform):\n","        super(UNetTestDataClass, self).__init__()\n","        \n","        images_list = os.listdir(images_path)\n","        images_list = [images_path+i for i in images_list]\n","        \n","        self.images_list = images_list\n","        self.transform = transform\n","        \n","    def __getitem__(self, index):\n","        img_path = self.images_list[index]\n","        data = Image.open(img_path)\n","        h = data.size[1]\n","        w = data.size[0]\n","        data = self.transform(data) / 255        \n","        return data, img_path, h, w\n","    \n","    def __len__(self):\n","        return len(self.images_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["path = '/kaggle/input/bkai-igh-neopolyp/test/test/'\n","unet_test_dataset = UNetTestDataClass(path, transform)\n","test_dataloader = DataLoader(unet_test_dataset, batch_size=8, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for i, (data, path, h, w) in enumerate(test_dataloader):\n","    img = data\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig, arr = plt.subplots(5, 2, figsize=(16, 12))\n","arr[0][0].set_title('Image');\n","arr[0][1].set_title('Predict');\n","\n","model.eval()\n","with torch.no_grad():\n","    predict = model(img.to(device))\n","\n","for i in range(5):\n","    arr[i][0].imshow(img[i].permute(1, 2, 0));\n","    arr[i][1].imshow(F.one_hot(torch.argmax(predict[i], 0).cpu()).float())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.eval()\n","if not os.path.isdir(\"/kaggle/working/predicted_masks\"):\n","    os.mkdir(\"/kaggle/working/predicted_masks\")\n","for _, (img, path, H, W) in enumerate(test_dataloader):\n","    a = path\n","    b = img\n","    h = H\n","    w = W\n","    \n","    with torch.no_grad():\n","        predicted_mask = model(b.to(device))\n","    for i in range(len(a)):\n","        image_id = a[i].split('/')[-1].split('.')[0]\n","        filename = image_id + \".png\"\n","        mask2img = Resize((h[i].item(), w[i].item()), interpolation=InterpolationMode.NEAREST)(ToPILImage()(F.one_hot(torch.argmax(predicted_mask[i], 0)).permute(2, 0, 1).float()))\n","        mask2img.save(os.path.join(\"/kaggle/working/predicted_masks/\", filename))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def rle_to_string(runs):\n","    return ' '.join(str(x) for x in runs)\n","\n","def rle_encode_one_mask(mask):\n","    pixels = mask.flatten()\n","    pixels[pixels > 0] = 255\n","    use_padding = False\n","    if pixels[0] or pixels[-1]:\n","        use_padding = True\n","        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n","        pixel_padded[1:-1] = pixels\n","        pixels = pixel_padded\n","    \n","    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n","    if use_padding:\n","        rle = rle - 1\n","    rle[1::2] = rle[1::2] - rle[:-1:2]\n","    return rle_to_string(rle)\n","\n","def mask2string(dir):\n","    ## mask --> string\n","    strings = []\n","    ids = []\n","    ws, hs = [[] for i in range(2)]\n","    for image_id in os.listdir(dir):\n","        id = image_id.split('.')[0]\n","        path = os.path.join(dir, image_id)\n","        print(path)\n","        img = cv2.imread(path)[:,:,::-1]\n","        h, w = img.shape[0], img.shape[1]\n","        for channel in range(2):\n","            ws.append(w)\n","            hs.append(h)\n","            ids.append(f'{id}_{channel}')\n","            string = rle_encode_one_mask(img[:,:,channel])\n","            strings.append(string)\n","    r = {\n","        'ids': ids,\n","        'strings': strings,\n","    }\n","    return r\n","\n","\n","MASK_DIR_PATH = '/kaggle/working/predicted_masks' # change this to the path to your output mask folder\n","dir = MASK_DIR_PATH\n","res = mask2string(dir)\n","df = pd.DataFrame(columns=['Id', 'Expected'])\n","df['Id'] = res['ids']\n","df['Expected'] = res['strings']\n","df.to_csv(r'output.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(df)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":2715462,"sourceId":30892,"sourceType":"competition"}],"dockerImageVersionId":30580,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
