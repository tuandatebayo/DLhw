{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:46:50.516110Z","iopub.status.busy":"2023-11-15T08:46:50.515804Z","iopub.status.idle":"2023-11-15T08:47:15.295034Z","shell.execute_reply":"2023-11-15T08:47:15.293890Z","shell.execute_reply.started":"2023-11-15T08:46:50.516083Z"},"trusted":true},"outputs":[],"source":["!pip install torchsummary\n","!pip install torchgeometry"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-15T08:47:15.297509Z","iopub.status.busy":"2023-11-15T08:47:15.297203Z","iopub.status.idle":"2023-11-15T08:47:19.979518Z","shell.execute_reply":"2023-11-15T08:47:19.978774Z","shell.execute_reply.started":"2023-11-15T08:47:15.297482Z"},"trusted":true},"outputs":[],"source":["from torchsummary import summary\n","from torchgeometry.losses import one_hot\n","import os\n","import pandas as pd\n","import numpy as np\n","from PIL import Image\n","import cv2\n","import time\n","import imageio\n","import matplotlib.pyplot as plt\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch import Tensor\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from torchvision.transforms import Resize, PILToTensor, ToPILImage, Compose, InterpolationMode\n","from collections import OrderedDict\n","import wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:47:19.980805Z","iopub.status.busy":"2023-11-15T08:47:19.980537Z","iopub.status.idle":"2023-11-15T08:47:20.941524Z","shell.execute_reply":"2023-11-15T08:47:20.940449Z","shell.execute_reply.started":"2023-11-15T08:47:19.980781Z"},"trusted":true},"outputs":[],"source":["!nvidia-smi -L"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:47:20.945361Z","iopub.status.busy":"2023-11-15T08:47:20.944761Z","iopub.status.idle":"2023-11-15T08:47:21.017875Z","shell.execute_reply":"2023-11-15T08:47:21.016862Z","shell.execute_reply.started":"2023-11-15T08:47:20.945323Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"markdown","metadata":{},"source":["# Parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:47:21.019373Z","iopub.status.busy":"2023-11-15T08:47:21.019092Z","iopub.status.idle":"2023-11-15T08:47:21.028163Z","shell.execute_reply":"2023-11-15T08:47:21.027257Z","shell.execute_reply.started":"2023-11-15T08:47:21.019348Z"},"trusted":true},"outputs":[],"source":["# Number of class in the data set (3: neoplastic, non neoplastic, background)\n","num_classes = 3\n","\n","# Number of epoch\n","epochs = 10\n","\n","# Hyperparameters for training \n","learning_rate = 2e-04\n","batch_size = 4\n","display_step = 50\n","\n","# Model path\n","checkpoint_path = '/kaggle/working/unet_model.pth'\n","pretrained_path = \"/kaggle/input/unet-checkpoint/unet_model.pth\"\n","# Initialize lists to keep track of loss and accuracy\n","loss_epoch_array = []\n","train_accuracy = []\n","test_accuracy = []\n","valid_accuracy = []"]},{"cell_type":"markdown","metadata":{},"source":["# Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:47:21.029565Z","iopub.status.busy":"2023-11-15T08:47:21.029285Z","iopub.status.idle":"2023-11-15T08:47:21.039066Z","shell.execute_reply":"2023-11-15T08:47:21.038260Z","shell.execute_reply.started":"2023-11-15T08:47:21.029535Z"},"trusted":true},"outputs":[],"source":["transform = Compose([Resize((800, 1120), interpolation=InterpolationMode.BILINEAR),\n","                     PILToTensor()])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:47:21.040567Z","iopub.status.busy":"2023-11-15T08:47:21.040253Z","iopub.status.idle":"2023-11-15T08:47:21.050493Z","shell.execute_reply":"2023-11-15T08:47:21.049637Z","shell.execute_reply.started":"2023-11-15T08:47:21.040537Z"},"trusted":true},"outputs":[],"source":["class UNetDataClass(Dataset):\n","    def __init__(self, images_path, masks_path, transform):\n","        super(UNetDataClass, self).__init__()\n","        \n","        images_list = os.listdir(images_path)\n","        masks_list = os.listdir(masks_path)\n","        \n","        images_list = [images_path + image_name for image_name in images_list]\n","        masks_list = [masks_path + mask_name for mask_name in masks_list]\n","        \n","        self.images_list = images_list\n","        self.masks_list = masks_list\n","        self.transform = transform\n","        \n","    def __getitem__(self, index):\n","        img_path = self.images_list[index]\n","        mask_path = self.masks_list[index]\n","        \n","        # Open image and mask\n","        data = Image.open(img_path)\n","        label = Image.open(mask_path)\n","        \n","        # Normalize\n","        data = self.transform(data) / 255\n","        label = self.transform(label) / 255\n","        \n","        label = torch.where(label>0.65, 1.0, 0.0)\n","        \n","        label[2, :, :] = 0.0001\n","        label = torch.argmax(label, 0).type(torch.int64)\n","        \n","        return data, label\n","    \n","    def __len__(self):\n","        return len(self.images_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:47:21.051814Z","iopub.status.busy":"2023-11-15T08:47:21.051532Z","iopub.status.idle":"2023-11-15T08:47:21.064380Z","shell.execute_reply":"2023-11-15T08:47:21.063530Z","shell.execute_reply.started":"2023-11-15T08:47:21.051791Z"},"trusted":true},"outputs":[],"source":["images_path = \"/kaggle/input/bkai-igh-neopolyp/train/train/\"\n","masks_path =  \"/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt/\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:47:21.065694Z","iopub.status.busy":"2023-11-15T08:47:21.065435Z","iopub.status.idle":"2023-11-15T08:47:21.248266Z","shell.execute_reply":"2023-11-15T08:47:21.247567Z","shell.execute_reply.started":"2023-11-15T08:47:21.065672Z"},"trusted":true},"outputs":[],"source":["unet_dataset = UNetDataClass(images_path, masks_path, transform)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:47:21.253127Z","iopub.status.busy":"2023-11-15T08:47:21.252874Z","iopub.status.idle":"2023-11-15T08:47:21.257027Z","shell.execute_reply":"2023-11-15T08:47:21.256170Z","shell.execute_reply.started":"2023-11-15T08:47:21.253105Z"},"trusted":true},"outputs":[],"source":["train_size = 0.8\n","valid_size = 0.2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:47:21.258259Z","iopub.status.busy":"2023-11-15T08:47:21.258008Z","iopub.status.idle":"2023-11-15T08:47:21.277811Z","shell.execute_reply":"2023-11-15T08:47:21.277143Z","shell.execute_reply.started":"2023-11-15T08:47:21.258238Z"},"trusted":true},"outputs":[],"source":["train_set, valid_set = random_split(unet_dataset, \n","                                    [int(train_size * len(unet_dataset)) , \n","                                     int(valid_size * len(unet_dataset))])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:47:21.279057Z","iopub.status.busy":"2023-11-15T08:47:21.278782Z","iopub.status.idle":"2023-11-15T08:47:21.283669Z","shell.execute_reply":"2023-11-15T08:47:21.282818Z","shell.execute_reply.started":"2023-11-15T08:47:21.279035Z"},"trusted":true},"outputs":[],"source":["train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n","valid_dataloader = DataLoader(valid_set, batch_size=batch_size, shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"markdown","metadata":{},"source":["**Encoder Block**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:47:21.285273Z","iopub.status.busy":"2023-11-15T08:47:21.284953Z","iopub.status.idle":"2023-11-15T08:47:21.294287Z","shell.execute_reply":"2023-11-15T08:47:21.293585Z","shell.execute_reply.started":"2023-11-15T08:47:21.285243Z"},"trusted":true},"outputs":[],"source":["class encoder_block(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(encoder_block, self).__init__()\n","        \n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding='same')\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding='same')\n","        \n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        \n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(p=0.3)\n","        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","        \n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        \n","        x = self.dropout(x)\n","        \n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x = self.relu(x)\n","        \n","        next_layer = self.max_pool(x)\n","        skip_layer = x\n","        \n","        return next_layer, skip_layer"]},{"cell_type":"markdown","metadata":{},"source":["**Decoder block**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:47:21.295444Z","iopub.status.busy":"2023-11-15T08:47:21.295203Z","iopub.status.idle":"2023-11-15T08:47:21.308417Z","shell.execute_reply":"2023-11-15T08:47:21.307694Z","shell.execute_reply.started":"2023-11-15T08:47:21.295423Z"},"trusted":true},"outputs":[],"source":["class decoder_block(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(decoder_block, self).__init__()\n","        \n","        self.transpose_conv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n","        \n","        self.conv1 = nn.Conv2d(2 * out_channels, out_channels, kernel_size=3, stride=1, padding='same')\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding='same')\n","        \n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        \n","        self.relu = nn.ReLU() \n","        self.dropout = nn.Dropout(p=0.3)\n","    \n","    def forward(self, x, skip_layer):\n","        x = self.transpose_conv(x)\n","        x = torch.cat([x, skip_layer], axis=1)\n","        \n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        \n","        x = self.dropout(x)\n","        \n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x = self.relu(x)\n","        \n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["**Bottle neck**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:47:21.310114Z","iopub.status.busy":"2023-11-15T08:47:21.309771Z","iopub.status.idle":"2023-11-15T08:47:21.318530Z","shell.execute_reply":"2023-11-15T08:47:21.317681Z","shell.execute_reply.started":"2023-11-15T08:47:21.310084Z"},"trusted":true},"outputs":[],"source":["class bottleneck_block(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(bottleneck_block, self).__init__()\n","        \n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding='same')\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding='same')\n","        \n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        \n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(p=0.3)\n","        \n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        \n","        x = self.dropout(x)\n","        \n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x = self.relu(x)\n","        \n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["**Unet model**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:47:21.319907Z","iopub.status.busy":"2023-11-15T08:47:21.319623Z","iopub.status.idle":"2023-11-15T08:47:21.331183Z","shell.execute_reply":"2023-11-15T08:47:21.330229Z","shell.execute_reply.started":"2023-11-15T08:47:21.319884Z"},"trusted":true},"outputs":[],"source":["# UNet model\n","class UNet(nn.Module):\n","    def __init__(self, n_class=3):\n","        super(UNet, self).__init__()\n","        # Encoder blocks\n","        self.enc1 = encoder_block(3, 64)\n","        self.enc2 = encoder_block(64, 128)\n","        self.enc3 = encoder_block(128, 256)\n","        self.enc4 = encoder_block(256, 512)\n","        \n","        # Bottleneck block\n","        self.bottleneck = bottleneck_block(512, 1024)\n","        \n","        # Decoder blocks\n","        self.dec1 = decoder_block(1024, 512)\n","        self.dec2 = decoder_block(512, 256)\n","        self.dec3 = decoder_block(256, 128)\n","        self.dec4 = decoder_block(128, 64)\n","        \n","        # 1x1 convolution\n","        self.out = nn.Conv2d(64, n_class, kernel_size=1, padding='same')\n","        \n","    def forward(self, image):\n","        n1, s1 = self.enc1(image)\n","        n2, s2 = self.enc2(n1)\n","        n3, s3 = self.enc3(n2)\n","        n4, s4 = self.enc4(n3)\n","        \n","        n5 = self.bottleneck(n4)\n","        \n","        n6 = self.dec1(n5, s4)\n","        n7 = self.dec2(n6, s3)\n","        n8 = self.dec3(n7, s2)\n","        n9 = self.dec4(n8, s1)\n","        \n","        output = self.out(n9)\n","        \n","        return output"]},{"cell_type":"markdown","metadata":{},"source":["# Loss function"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:47:21.344104Z","iopub.status.busy":"2023-11-15T08:47:21.343800Z","iopub.status.idle":"2023-11-15T08:47:21.356260Z","shell.execute_reply":"2023-11-15T08:47:21.355454Z","shell.execute_reply.started":"2023-11-15T08:47:21.344082Z"},"trusted":true},"outputs":[],"source":["class FocalLoss(nn.Module):\n","    def __init__(self, weights=None, gamma=2.0):\n","        super(FocalLoss, self).__init__()\n","        self.gamma = gamma\n","        self.weights = weights\n","\n","    def forward(\n","        self,\n","        input: torch.Tensor,\n","        target: torch.Tensor\n","    ) -> torch.Tensor:\n","        if not torch.is_tensor(input):\n","            raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n","                            .format(type(input)))\n","        if not len(input.shape) == 4:\n","            raise ValueError(\"Invalid input shape, we expect BxNxHxW. Got: {}\"\n","                             .format(input.shape))\n","        if not input.shape[-2:] == target.shape[-2:]:\n","            raise ValueError(\"Input and target shapes must be the same. Got: {}\"\n","                             .format(input.shape, input.shape))\n","        if not input.device == target.device:\n","            raise ValueError(\n","                \"Input and target must be on the same device. Got: {}\" .format(\n","                    input.device, target.device))\n","        if self.weights is not None and not self.weights.shape[1] == input.shape[1]:\n","            raise ValueError(\"The number of weights must equal the number of classes\")\n","        if self.weights is not None and not torch.sum(self.weights).item() == 1:\n","            raise ValueError(\"The sum of all weights must equal 1\")\n","            \n","        # Focal loss\n","        ce_loss = F.cross_entropy(input, target, weight=self.weights)\n","        pt = torch.exp(-ce_loss)\n","        focal_loss = (1 - pt) ** self.gamma * ce_loss\n","\n","        return focal_loss"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"markdown","metadata":{},"source":["**Initialize weights**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:47:21.357631Z","iopub.status.busy":"2023-11-15T08:47:21.357323Z","iopub.status.idle":"2023-11-15T08:47:21.366429Z","shell.execute_reply":"2023-11-15T08:47:21.365614Z","shell.execute_reply.started":"2023-11-15T08:47:21.357600Z"},"trusted":true},"outputs":[],"source":["def weights_init(model):\n","    if isinstance(model, nn.Linear):\n","        # Xavier Distribution\n","        torch.nn.init.xavier_uniform_(model.weight)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:47:21.367727Z","iopub.status.busy":"2023-11-15T08:47:21.367470Z","iopub.status.idle":"2023-11-15T08:47:21.377363Z","shell.execute_reply":"2023-11-15T08:47:21.376553Z","shell.execute_reply.started":"2023-11-15T08:47:21.367706Z"},"trusted":true},"outputs":[],"source":["def save_model(model, optimizer, path):\n","    checkpoint = {\n","        \"model\": model.state_dict(),\n","        \"optimizer\": optimizer.state_dict(),\n","    }\n","    torch.save(checkpoint, path)\n","\n","def load_model(model, optimizer, path):\n","    checkpoint = torch.load(path)\n","    model.load_state_dict(checkpoint[\"model\"])\n","    optimizer.load_state_dict(checkpoint['optimizer'])\n","    return model, optimizer"]},{"cell_type":"markdown","metadata":{},"source":["**Train model**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:47:21.378733Z","iopub.status.busy":"2023-11-15T08:47:21.378474Z","iopub.status.idle":"2023-11-15T08:47:21.392417Z","shell.execute_reply":"2023-11-15T08:47:21.391585Z","shell.execute_reply.started":"2023-11-15T08:47:21.378712Z"},"trusted":true},"outputs":[],"source":["# Train function for each epoch\n","def train(train_dataloader, valid_dataloader,learing_rate_scheduler, epoch, display_step):\n","    print(f\"Start epoch #{epoch+1}, learning rate for this epoch: {learing_rate_scheduler.get_last_lr()}\")\n","    start_time = time.time()\n","    train_loss_epoch = 0\n","    test_loss_epoch = 0\n","    last_loss = 999999999\n","    model.train()\n","    for i, (data,targets) in enumerate(train_dataloader):\n","        \n","        # Load data into GPU\n","        data, targets = data.to(device), targets.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(data)\n","\n","        # Backpropagation, compute gradients\n","        loss = loss_function(outputs, targets.long())\n","        loss.backward()\n","\n","        # Apply gradients\n","        optimizer.step()\n","        \n","        # Save loss\n","        train_loss_epoch += loss.item()\n","        if (i+1) % display_step == 0:\n","#             accuracy = float(test(test_loader))\n","            print('Train Epoch: {} [{}/{} ({}%)]\\tLoss: {:.4f}'.format(\n","                epoch + 1, (i+1) * len(data), len(train_dataloader.dataset), 100 * (i+1) * len(data) / len(train_dataloader.dataset), \n","                loss.item()))\n","                  \n","    print(f\"Done epoch #{epoch+1}, time for this epoch: {time.time()-start_time}s\")\n","    train_loss_epoch/= (i + 1)\n","    \n","    # Evaluate the validation set\n","    model.eval()\n","    with torch.no_grad():\n","        for data, target in valid_dataloader:\n","            data, target = data.to(device), target.to(device)\n","            test_output = model(data)\n","            test_loss = loss_function(test_output, target)\n","            test_loss_epoch += test_loss.item()\n","            \n","    test_loss_epoch/= (i+1)\n","    \n","    return train_loss_epoch , test_loss_epoch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:47:21.393634Z","iopub.status.busy":"2023-11-15T08:47:21.393338Z","iopub.status.idle":"2023-11-15T08:47:21.404436Z","shell.execute_reply":"2023-11-15T08:47:21.403610Z","shell.execute_reply.started":"2023-11-15T08:47:21.393612Z"},"trusted":true},"outputs":[],"source":["# Test function\n","def test(dataloader):\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for i, (data, targets) in enumerate(dataloader):\n","            data, targets = data.to(device), targets.to(device)\n","            outputs = model(data)\n","            _, pred = torch.max(outputs, 1)\n","            test_loss += targets.size(0)\n","            correct += torch.sum(pred == targets).item()\n","    return 100.0 * correct / test_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:47:21.405750Z","iopub.status.busy":"2023-11-15T08:47:21.405415Z","iopub.status.idle":"2023-11-15T08:47:24.729642Z","shell.execute_reply":"2023-11-15T08:47:24.728572Z","shell.execute_reply.started":"2023-11-15T08:47:21.405725Z"},"trusted":true},"outputs":[],"source":["model = UNet()\n","model.apply(weights_init)\n","model = nn.DataParallel(model)\n","# checkpoint = torch.load(pretrained_path)\n","\n","# new_state_dict = OrderedDict()\n","# for k, v in checkpoint['model'].items():\n","#     name = k[7:] # remove `module.`\n","#     new_state_dict[name] = v\n","# # load params\n","# model.load_state_dict(new_state_dict)\n","# model = nn.DataParallel(model)\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:47:24.730979Z","iopub.status.busy":"2023-11-15T08:47:24.730702Z","iopub.status.idle":"2023-11-15T08:47:25.200005Z","shell.execute_reply":"2023-11-15T08:47:25.199084Z","shell.execute_reply.started":"2023-11-15T08:47:24.730956Z"},"trusted":true},"outputs":[],"source":["count = 0\n","for root, folders, filenames in os.walk('/kaggle/input'):\n","   print(root, folders)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:47:25.202051Z","iopub.status.busy":"2023-11-15T08:47:25.201282Z","iopub.status.idle":"2023-11-15T08:47:25.208374Z","shell.execute_reply":"2023-11-15T08:47:25.207425Z","shell.execute_reply.started":"2023-11-15T08:47:25.202013Z"},"trusted":true},"outputs":[],"source":["weights = torch.Tensor([[0.4, 0.55, 0.05]]).cuda()\n","loss_function = FocalLoss(weights)\n","\n","# Define the optimizer (Adam optimizer)\n","optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n","# optimizer.load_state_dict(checkpoint['optimizer'])\n","\n","# Learning rate scheduler\n","learing_rate_scheduler = lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.6)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:47:25.209687Z","iopub.status.busy":"2023-11-15T08:47:25.209429Z","iopub.status.idle":"2023-11-15T08:47:25.417197Z","shell.execute_reply":"2023-11-15T08:47:25.416390Z","shell.execute_reply.started":"2023-11-15T08:47:25.209664Z"},"trusted":true},"outputs":[],"source":["save_model(model, optimizer, checkpoint_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T08:47:25.418612Z","iopub.status.busy":"2023-11-15T08:47:25.418347Z"},"trusted":true},"outputs":[],"source":["wandb.login(\n","    # set the wandb project where this run will be logged\n","#     project= \"PolypSegment\", \n","    key = \"bc244be18c8a532993c559a3fa44acd1cd47486a\",\n",")\n","wandb.init(\n","    project = \"PolypSegment\"\n",")\n","# Training loop\n","train_loss_array = []\n","test_loss_array = []\n","last_loss = 9999999999999\n","for epoch in range(epochs):\n","    train_loss_epoch = 0\n","    test_loss_epoch = 0\n","    (train_loss_epoch, test_loss_epoch) = train(train_dataloader, \n","                                              valid_dataloader, \n","                                              learing_rate_scheduler, epoch, display_step)\n","    \n","    if test_loss_epoch < last_loss:\n","        save_model(model, optimizer, checkpoint_path)\n","        last_loss = test_loss_epoch\n","        \n","    learing_rate_scheduler.step()\n","    train_loss_array.append(train_loss_epoch)\n","    test_loss_array.append(test_loss_epoch)\n","    wandb.log({\"Train loss\": train_loss_epoch, \"Valid loss\": test_loss_epoch})\n","#     train_accuracy.append(test(train_loader))\n","#     valid_accuracy.append(test(test_loader))\n","#     print(\"Epoch {}: loss: {:.4f}, train accuracy: {:.4f}, valid accuracy:{:.4f}\".format(epoch + 1, \n","#                                         train_loss_array[-1], train_accuracy[-1], valid_accuracy[-1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Plot the learning cure"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# load_model(model, checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.rcParams['figure.dpi'] = 90\n","plt.rcParams['figure.figsize'] = (6, 4)\n","epochs_array = range(epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plot Training and Test loss\n","plt.plot(epochs_array, train_loss_array, 'g', label='Training loss')\n","# plt.plot(epochs_array, test_loss_array, 'b', label='Test loss')\n","plt.title('Training and Test loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["**Infer**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# from torch.jit import load\n","# model = UNet()\n","# optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n","\n","# checkpoint = torch.load(pretrained_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# optimizer.load_state_dict(checkpoint['optimizer'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# from collections import OrderedDict\n","# new_state_dict = OrderedDict()\n","# for k, v in checkpoint['model'].items():\n","#     name = k[7:] # remove `module.`\n","#     new_state_dict[name] = v\n","# # load params\n","# model.load_state_dict(new_state_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["**Visualize results**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for i, (data, label) in enumerate(train_dataloader):\n","    img = data\n","    mask = label\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig, arr = plt.subplots(4, 3, figsize=(16, 12))\n","arr[0][0].set_title('Image')\n","arr[0][1].set_title('Segmentation')\n","arr[0][2].set_title('Predict')\n","\n","model.eval()\n","with torch.no_grad():\n","    predict = model(img)\n","\n","for i in range(4):\n","    arr[i][0].imshow(img[i].permute(1, 2, 0));\n","    \n","    arr[i][1].imshow(F.one_hot(mask[i]).float())\n","    \n","    arr[i][2].imshow(F.one_hot(torch.argmax(predict[i], 0).cpu()).float())"]},{"cell_type":"markdown","metadata":{},"source":["**Create submission**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["transform = Compose([Resize((800, 1120), interpolation=InterpolationMode.BILINEAR),\n","                     PILToTensor()])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class UNetTestDataClass(Dataset):\n","    def __init__(self, images_path, transform):\n","        super(UNetTestDataClass, self).__init__()\n","        \n","        images_list = os.listdir(images_path)\n","        images_list = [images_path+i for i in images_list]\n","        \n","        self.images_list = images_list\n","        self.transform = transform\n","        \n","    def __getitem__(self, index):\n","        img_path = self.images_list[index]\n","        data = Image.open(img_path)\n","        h = data.size[1]\n","        w = data.size[0]\n","        data = self.transform(data) / 255        \n","        return data, img_path, h, w\n","    \n","    def __len__(self):\n","        return len(self.images_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["path = '/kaggle/input/bkai-igh-neopolyp/test/test/'\n","unet_test_dataset = UNetTestDataClass(path, transform)\n","test_dataloader = DataLoader(unet_test_dataset, batch_size=8, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for i, (data, path, h, w) in enumerate(test_dataloader):\n","    img = data\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig, arr = plt.subplots(5, 2, figsize=(16, 12))\n","arr[0][0].set_title('Image');\n","arr[0][1].set_title('Predict');\n","\n","model.eval()\n","with torch.no_grad():\n","    predict = model(img)\n","\n","for i in range(5):\n","    arr[i][0].imshow(img[i].permute(1, 2, 0));\n","    arr[i][1].imshow(F.one_hot(torch.argmax(predict[i], 0).cpu()).float())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.eval()\n","if not os.path.isdir(\"/kaggle/working/predicted_masks\"):\n","    os.mkdir(\"/kaggle/working/predicted_masks\")\n","for _, (img, path, H, W) in enumerate(test_dataloader):\n","    a = path\n","    b = img\n","    h = H\n","    w = W\n","    \n","    with torch.no_grad():\n","        predicted_mask = model(b)\n","    for i in range(len(a)):\n","        image_id = a[i].split('/')[-1].split('.')[0]\n","        filename = image_id + \".png\"\n","        mask2img = Resize((h[i].item(), w[i].item()), interpolation=InterpolationMode.NEAREST)(ToPILImage()(F.one_hot(torch.argmax(predicted_mask[i], 0)).permute(2, 0, 1).float()))\n","        mask2img.save(os.path.join(\"/kaggle/working/predicted_masks/\", filename))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def rle_to_string(runs):\n","    return ' '.join(str(x) for x in runs)\n","\n","def rle_encode_one_mask(mask):\n","    pixels = mask.flatten()\n","    pixels[pixels > 0] = 255\n","    use_padding = False\n","    if pixels[0] or pixels[-1]:\n","        use_padding = True\n","        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n","        pixel_padded[1:-1] = pixels\n","        pixels = pixel_padded\n","    \n","    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n","    if use_padding:\n","        rle = rle - 1\n","    rle[1::2] = rle[1::2] - rle[:-1:2]\n","    return rle_to_string(rle)\n","\n","def mask2string(dir):\n","    ## mask --> string\n","    strings = []\n","    ids = []\n","    ws, hs = [[] for i in range(2)]\n","    for image_id in os.listdir(dir):\n","        id = image_id.split('.')[0]\n","        path = os.path.join(dir, image_id)\n","        print(path)\n","        img = cv2.imread(path)[:,:,::-1]\n","        h, w = img.shape[0], img.shape[1]\n","        for channel in range(2):\n","            ws.append(w)\n","            hs.append(h)\n","            ids.append(f'{id}_{channel}')\n","            string = rle_encode_one_mask(img[:,:,channel])\n","            strings.append(string)\n","    r = {\n","        'ids': ids,\n","        'strings': strings,\n","    }\n","    return r\n","\n","\n","MASK_DIR_PATH = '/kaggle/working/predicted_masks' # change this to the path to your output mask folder\n","dir = MASK_DIR_PATH\n","res = mask2string(dir)\n","df = pd.DataFrame(columns=['Id', 'Expected'])\n","df['Id'] = res['ids']\n","df['Expected'] = res['strings']\n","df.to_csv(r'output.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(df)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":2715462,"sourceId":30892,"sourceType":"competition"}],"dockerImageVersionId":30580,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
